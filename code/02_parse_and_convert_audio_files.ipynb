{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and Convert Audio Files\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydub\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence, detect_silence\n",
    "from pydub.playback import play\n",
    "import time\n",
    "# import dolby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define ffmpeg and ffprobe Path for PyDub Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydub.AudioSegment.converter = '/Users/YOUR-USER/anaconda3/bin/ffmpeg'\n",
    "pydub.AudioSegment.ffmpeg = '/Users/YOUR-USER/anaconda3/bin/ffmpeg'\n",
    "pydub.AudioSegment.ffprobe = '/Users/YOUR-USER/anaconda3/bin/ffprobe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the pydub Python package to parse and segment our mp3 files. Pydub accepts mp3 files and has methods that detect silence, detect audio, and split the mp3 files based on silence. We utilized the last method to pull samples of audio from our data. There are two parameters we passed in as well -- min_silence_len and silence_thresh. These determine how long a pause needs to be in milliseconds before itâ€™s registered as silence, and how loud something needs to be in dbFS before its registered as audio. We played with a few min_silence_len and silence_thresh values, but settled on 2.5 seconds and -16dbFS for our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the audio\n",
    "We used dolby's dialogue enhancement API to clean up the audio in 3 ways:\n",
    "<details><summary>Noise Reduction</summary>\n",
    "    Capturing audio can pick up a variety of noises that distract from the dialog the listener wants to focus on.  The Noise Processing API helps you fix audio recorded in noisy environments or with poor equipment to create consistency across your recordings.</details>\n",
    "<details><summary>Sibilance Attenuation</summary>\n",
    "    To create studio sound for the dialog in recorded audio, it is useful to detect and reduce the sibilance captured by the microphone.  This is a characteristic of harsh consonant sounds like \"s\", \"sh\", \"x\", \"ch\", \"t\", and \"th\". </details>\n",
    "<details><summary>Tone Repair</summary>\n",
    "    In order to give the audio more presence and authority it is valuable to modify the tone.  The Tone Processing API helps with equalization to shape the audio from your recorded files to match a listener profile.  This is especially important when the original audio is limited in tone, as is the case with police radio, which is why it often has a thin, tinny characteristic to the voices.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dolby API requires the audio files be available online to fetch and save repaired audio files.  We used an Amazon Web Services server to upload and host the files, which were then saved back into the repo.  The code below creates a flow of the audio files through noise reduction, then sibilance, and then tone correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path may vary\n",
    "files = os.listdir('../testing/mp3_downloads/')[1:]\n",
    "\n",
    "# Folder names on the AWS server.  Audio files will be opened and saved into the subsequent\n",
    "# folder as they flow through the dolby API processes.\n",
    "chain = [\"rough\",\"noise\",\"sibilance\",\"tone\"]\n",
    "\n",
    "# These processes are described above, see https://dlby.io/documentation/noise/getting-started\n",
    "# for documentation\n",
    "process = [dolby.noise, dolby.sibilance, dolby.tone]\n",
    "\n",
    "for i,link in enumerate(chain[1:]):\n",
    "    \n",
    "    # URL link is to AWS server\n",
    "    for name in files:\n",
    "        token = {\n",
    "        \"input\": {\n",
    "        \"url\": f\"https://username.s3-us-west-1.amazonaws.com/{chain[i]}/{name}\",\n",
    "        \"auth\": {\n",
    "          \"key\": \"XXXX\",                # AWS Key\n",
    "          \"secret\": \"XXXXXxxXX\",        # AWS Secret\n",
    "    #       \"token\": \"XXXX\"        }    # AWS Token\n",
    "      },\n",
    "      \"output\": {\n",
    "        \"url\": f\"s3://username/{link}/{name}\",\n",
    "        \"auth\": {\n",
    "          \"key\": \"XXXX\",                # AWS Key\n",
    "          \"secret\": \"XXXXxxXXXX\",       # AWS Secret\n",
    "    #       \"token\": \"XXXxXXXX\"     }}} # AWS Token\n",
    "\n",
    "        process[i](key='XxxXXxX',       # Dolby API Key\n",
    "                    url='https://api.dolby.com',\n",
    "                    input_file = f\"https://username.s3-us-west-1.amazonaws.com/{chain[i]}/{name}\",\n",
    "                    output_file= f\"s3://username/{link}/{name}\",   # AWS folders with Audio\n",
    "                    more = token\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse Through Files and Convert to .wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing File: 0\n",
      "File Lenght: 962.014s\n",
      "File Average Loudness: -29.04 dBFS\n",
      "File 0 RunTime: 150.41s\n",
      " \n",
      "Analyzing File: 1\n",
      "File Lenght: 871.996s\n",
      "File Average Loudness: -28.41 dBFS\n",
      "File 1 RunTime: 155.04s\n",
      " \n",
      "Analyzing File: 2\n",
      "File Lenght: 818.0s\n",
      "File Average Loudness: -28.67 dBFS\n",
      "File 2 RunTime: 134.34s\n",
      " \n",
      "Analyzing File: 3\n",
      "File Lenght: 771.999s\n",
      "File Average Loudness: -28.2 dBFS\n",
      "File 3 RunTime: 127.67s\n",
      " \n",
      "Analyzing File: 4\n",
      "File Lenght: 856.009s\n",
      "File Average Loudness: -28.64 dBFS\n",
      "File 4 RunTime: 132.14s\n",
      " \n",
      "Total RunTime:699.6s\n"
     ]
    }
   ],
   "source": [
    "# Starting time\n",
    "t0 = time.time()\n",
    "\n",
    "# Insert file path with mp3 downloads\n",
    "file_path = '../testing/mp3_clean/'\n",
    "\n",
    "# Loop through all files in file_path\n",
    "for n, file in enumerate(os.listdir(file_path)):\n",
    "    \n",
    "    # Starting time\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # If file extension is .mp3\n",
    "    if file.endswith('.mp3'):\n",
    "        \n",
    "        # Define audio to be split\n",
    "        sound_file = AudioSegment.from_mp3(file_path + file)\n",
    "        \n",
    "        # Print file n, lenght and avg loudness for each file\n",
    "        print(f'Analyzing File: {n}')\n",
    "        print(f'File Lenght: {len(sound_file) / 1000}s')\n",
    "        print(f'File Average Loudness: {round(sound_file.dBFS, 2)} dBFS')\n",
    "        \n",
    "                \n",
    "        # Split files into smaller chunks\n",
    "        chunks = split_on_silence(sound_file,                           # sound_file to be split\n",
    "                                  min_silence_len = 4_000,              # min_silence_len in ms\n",
    "                                  silence_thresh = sound_file.dBFS - 2, # silence thresh based on avg loudness\n",
    "                                  keep_silence = 100)                   # add 100ms of silence before and after\n",
    "        \n",
    "        # Loop through all chunks and select the ones that are at least 2 seconds and less than 60 seconds\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            \n",
    "            #  Export chunks to that are at least 5 seconds and less than 60 seconds to .wav\n",
    "            if (len(chunk) > 5_000) and (len(chunk) < 60_000):\n",
    "                chunk.export(f\"../testing/wav_clean_converted_files/{file}_{i}.wav\", format=\"wav\")\n",
    "        \n",
    "        # Starting time\n",
    "        print(f'File {n} RunTime: {round(time.time() - t1, 2)}s')\n",
    "        print(' ')\n",
    "        \n",
    "# Print total runtime\n",
    "print(f'Total RunTime:{round(time.time() - t0, 2)}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Adapted from:** [Mitchell Bohman, Nour Zahlan, and Masiur Abik](https://github.com/mchbmn/radio-to-location) and [Joseph Hopkins, Carol, Chiu, Anthony Chapman, Kwamae Delva](https://github.com/delvakwa/police_radio_to_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
